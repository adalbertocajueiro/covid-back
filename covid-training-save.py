#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Classificação de Coronavírus Binário.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/164fuZk7Oe8AUFxoDQL7fEmH2Mmw-HH9z

Código baseado no post de Adrian Yijie Xu disponível em: https://towardsdatascience.com/detecting-covid-19-induced-pneumonia-from-chest-x-rays-with-transfer-learning-an-implementation-311484e6afc1

Codigo de treinamento da rede. Para criar a rede e salvar em um arquivo,
precisa apenas executar este código (assumindo que os dados já foram baixados e 
descompactados em uma pasta conveniente)

"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras import optimizers
import os

os.environ['KMP_DUPLICATE_LIB_OK']='True'

""" 
codigo par afazer o download e descompactar os dados a serem utilizados

!gdown https://drive.google.com/uc?id=1coM7x3378f-Ou2l6Pg2wldaOI7Dntu1a

!unzip Covid_Data_GradientCrescent.zip
"""

# pasta contendo os dados de treinamento baixados
train_dir = '/Users/adalbertocajueiro/Downloads/two/train'
img_size = (150, 150)


train_datagen = ImageDataGenerator(rescale=1./255,
 rotation_range=50,
 width_shift_range=0.2,
 height_shift_range=0.2,
 shear_range=0.25,
 zoom_range=0.1,
 validation_split = 0.2,
 fill_mode='nearest')

train_batches = train_datagen.flow_from_directory(train_dir,
 target_size=img_size,
 shuffle=True,
 batch_size=10,
 subset = "training",
 seed=42,
 class_mode="binary",
  )

valid_batches = train_datagen.flow_from_directory(train_dir,
 target_size=img_size,
 shuffle=True,
 batch_size=10,
 subset = "validation",
 seed=42,
 class_mode="binary",
  )

conv_base = VGG16(weights='imagenet', include_top=False,input_shape=(150, 150, 3))
conv_base.trainable = False
model = tf.keras.models.Sequential()
model.add(conv_base)
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(256, activation='relu'))
model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=0.0005), metrics=['acc'])

result=model.fit(train_batches,
 steps_per_epoch = train_batches.n//train_batches.batch_size,
 validation_data = valid_batches,
 validation_steps = valid_batches.n//valid_batches.batch_size,
 epochs = 20,
 )

model.save("model.h5")

print("Model saved to disk")